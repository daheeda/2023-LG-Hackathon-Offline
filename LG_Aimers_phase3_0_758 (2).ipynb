{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DH_c0KCcTXWJ",
    "outputId": "e9622d04-560e-4417-a016-9729f9bb5231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.13.1)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qe2o-O4u6OXn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import catboost\n",
    "from catboost import *\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mq9ums2L76Ph"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/LG_Aimers_Phase_3/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/LG_Aimers_Phase_3/test.csv')\n",
    "submit = pd.read_csv('/content/drive/MyDrive/LG_Aimers_Phase_3/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFv1EzkV-DlG",
    "outputId": "1e8fb1d8-c5bc-418f-e790-89f3c9d8f02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525066667\n",
      "0.525085714\n",
      "0.534842857\n",
      "0.534950794\n"
     ]
    }
   ],
   "source": [
    "print(train[train['Y_Class'] == 0]['Y_Quality'].max())\n",
    "print(train[train['Y_Class'] == 1]['Y_Quality'].min())\n",
    "print(train[train['Y_Class'] == 1]['Y_Quality'].max())\n",
    "print(train[train['Y_Class'] == 2]['Y_Quality'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87Q1AMDI_7S_"
   },
   "outputs": [],
   "source": [
    "def del_columns(train, test):\n",
    "    col_list = train.columns\n",
    "    nan_list = []\n",
    "    nan_cnt = []\n",
    "    nan_col = []\n",
    "    full_list = []\n",
    "    for col in col_list:\n",
    "        if train[col].isnull().sum() == 0 :\n",
    "            full_list.append(col)\n",
    "            continue\n",
    "        nan_list.append([col, train[col].isnull().sum()])\n",
    "        nan_cnt.append(train[col].isnull().sum())\n",
    "        nan_col.append(col)\n",
    "\n",
    "    del_col = []\n",
    "    for col in nan_list :\n",
    "        if col[1] == len(train) :\n",
    "            del_col.append(col[0])\n",
    "    train = train.drop(columns=del_col)\n",
    "    test = test.drop(columns=del_col)\n",
    "\n",
    "    del_col = []\n",
    "    col_list = train.describe().columns\n",
    "    for col in col_list :\n",
    "        if col == 'Y_Class':\n",
    "            continue\n",
    "        if col == 'Y_Quality':\n",
    "            continue\n",
    "        if col == 'LINE':\n",
    "            continue\n",
    "        if col == 'PRODUCT_CODE':\n",
    "            continue\n",
    "        if train[col].nunique()==1 :\n",
    "            del_col.append(col)\n",
    "    train = train.drop(columns=del_col)\n",
    "    test = test.drop(columns=del_col)\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def make_train_test_dataset(train,test):\n",
    "    \n",
    "    '''\n",
    "    트레인데이터, 학습데이터 셋 만들기\n",
    "    '''\n",
    "    \n",
    "    train_x = train.drop(columns=['PRODUCT_ID','PRODUCT_CODE','Y_Class','Y_Quality'])\n",
    "    test_x = test.drop(columns=['PRODUCT_ID','PRODUCT_CODE'])\n",
    "    train_y = train['Y_Quality']\n",
    "    train_w = train[['Y_Class']]\n",
    "    return train_x, test_x, train_y, train_w\n",
    "\n",
    "\n",
    "def fillna(train,test,value):\n",
    "    train = train.fillna(value)\n",
    "    test = test.fillna(value)\n",
    "    return train,test\n",
    "\n",
    "def labelencoder(train,test,col_list):\n",
    "    \n",
    "    qual_col = col_list\n",
    "    for i in qual_col:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(train[i])\n",
    "        train[i] = le.transform(train[i])\n",
    "\n",
    "        for label in np.unique(test[i]): \n",
    "            if label not in le.classes_: \n",
    "                le.classes_ = np.append(le.classes_, label)\n",
    "        test[i] = le.transform(test[i]) \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXezYT84A3ov"
   },
   "outputs": [],
   "source": [
    "#train, test = del_columns(train,test)\n",
    "train, test = fillna(train,test,-999999)\n",
    "#train_x, test_x, train_y, train_w = make_train_test_dataset(train,test)\n",
    "#train_x, test_x = labelencoder(train_x,test_x,['LINE'])\n",
    "train['PRODUCT_CODE'] = train['PRODUCT_CODE'].astype('category')\n",
    "train['LINE'] = train['LINE'].astype('category')\n",
    "\n",
    "test['PRODUCT_CODE'] = test['PRODUCT_CODE'].astype('category')\n",
    "test['LINE'] = test['LINE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mxkx7EXPpSB"
   },
   "outputs": [],
   "source": [
    "submit_r = pd.concat([submit,test['PRODUCT_CODE']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnlk4FtqLTzs"
   },
   "outputs": [],
   "source": [
    "train_A = train[train['PRODUCT_CODE'] == 'A_31']\n",
    "train_T = train[train['PRODUCT_CODE'] == 'T_31']\n",
    "train_O = train[train['PRODUCT_CODE'] == 'O_31']\n",
    "\n",
    "test_A = test[test['PRODUCT_CODE'] == 'A_31']\n",
    "test_T = test[test['PRODUCT_CODE'] == 'T_31']\n",
    "test_O = test[test['PRODUCT_CODE'] == 'O_31']\n",
    "\n",
    "submit_A = submit_r[submit_r['PRODUCT_CODE'] == 'A_31']\n",
    "submit_T = submit_r[submit_r['PRODUCT_CODE'] == 'T_31']\n",
    "submit_O = submit_r[submit_r['PRODUCT_CODE'] == 'O_31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4J4c1hzLiZc"
   },
   "outputs": [],
   "source": [
    "train_A_1 = train_A[(train_A['X_230'] == -999999) & (train_A['X_231'] == -999999) & (train_A['X_232'] == -999999) & (train_A['X_233'] == -999999) & (train_A['X_234'] == -999999) & (train_A['X_235'] == -999999) & (train_A['X_236'] == -999999)]\n",
    "train_T_1 = train_T[(train_T['X_3000'] == -999999) & (train_T['X_3001'] == -999999) & (train_T['X_3002'] == -999999) & (train_T['X_3003'] == -999999) & (train_T['X_3004'] == -999999) & (train_T['X_3005'] == -999999) & (train_T['X_3006'] == -999999)]\n",
    "#train_O_1 = train_O[(train_O['X_93'] == -999999) & (train_O['X_94'] == -999999) & (train_O['X_95'] == -999999) & (train_O['X_96'] == -999999)]\n",
    "\n",
    "train_A_2 = train_A[(train_A['X_230'] != -999999) & (train_A['X_231'] != -999999) & (train_A['X_232'] != -999999) & (train_A['X_233'] != -999999) & (train_A['X_234'] != -999999) & (train_A['X_235'] != -999999) & (train_A['X_236'] != -999999)]\n",
    "train_T_2 = train_T[(train_T['X_3000'] != -999999) & (train_T['X_3001'] != -999999) & (train_T['X_3002'] != -999999) & (train_T['X_3003'] != -999999) & (train_T['X_3004'] != -999999) & (train_T['X_3005'] != -999999) & (train_T['X_3006'] != -999999)]\n",
    "#train_O_2 = train_O[(train_O['X_93'] != -999999) & (train_O['X_94'] != -999999) & (train_O['X_95'] != -999999) & (train_O['X_96'] != -999999)]\n",
    "\n",
    "test_A_1 = test_A[(test_A['X_230'] == -999999) & (test_A['X_231'] == -999999) & (test_A['X_232'] == -999999) & (test_A['X_233'] == -999999) & (test_A['X_234'] == -999999) & (test_A['X_235'] == -999999) & (test_A['X_236'] == -999999)]\n",
    "test_T_1 = test_T[(test_T['X_3000'] == -999999) & (test_T['X_3001'] == -999999) & (test_T['X_3002'] == -999999) & (test_T['X_3003'] == -999999) & (test_T['X_3004'] == -999999) & (test_T['X_3005'] == -999999) & (test_T['X_3006'] == -999999)]\n",
    "#test_O_1 = test_O[(test_O['X_93'] == -999999) & (test_O['X_94'] == -999999) & (test_O['X_95'] == -999999) & (test_O['X_96'] == -999999)]\n",
    "\n",
    "test_A_2 = test_A[(test_A['X_230'] != -999999) & (test_A['X_231'] != -999999) & (test_A['X_232'] != -999999) & (test_A['X_233'] != -999999) & (test_A['X_234'] != -999999) & (test_A['X_235'] != -999999) & (test_A['X_236'] != -999999)]\n",
    "test_T_2 = test_T[(test_T['X_3000'] != -999999) & (test_T['X_3001'] != -999999) & (test_T['X_3002'] != -999999) & (test_T['X_3003'] != -999999) & (test_T['X_3004'] != -999999) & (test_T['X_3005'] != -999999) & (test_T['X_3006'] != -999999)]\n",
    "#test_O_2 = test_O[(test_O['X_93'] != -999999) & (test_O['X_94'] != -999999) & (test_O['X_95'] != -999999) & (test_O['X_96'] != -999999)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3uphZWCS0np"
   },
   "outputs": [],
   "source": [
    "train_A_1_indices = train_A.index[(train_A['X_230'] == -999999) & (train_A['X_231'] == -999999) & (train_A['X_232'] == -999999) & (train_A['X_233'] == -999999) & (train_A['X_234'] == -999999) & (train_A['X_235'] == -999999) & (train_A['X_236'] == -999999)]\n",
    "train_T_1_indices = train_T.index[(train_T['X_3000'] == -999999) & (train_T['X_3001'] == -999999) & (train_T['X_3002'] == -999999) & (train_T['X_3003'] == -999999) & (train_T['X_3004'] == -999999) & (train_T['X_3005'] == -999999) & (train_T['X_3006'] == -999999)]\n",
    "#train_O_1_indices = train_O.index[(train_O['X_93'] == -999999) & (train_O['X_94'] == -999999) & (train_O['X_95'] == -999999) & (train_O['X_96'] == -999999)]\n",
    "\n",
    "train_A_1 = train_A.loc[train_A_1_indices]\n",
    "train_T_1 = train_T.loc[train_T_1_indices]\n",
    "#train_O_1 = train_O.loc[train_O_1_indices]\n",
    "\n",
    "train_A_2_indices = train_A.index[(train_A['X_230'] != -999999) | (train_A['X_231'] != -999999) | (train_A['X_232'] != -999999) | (train_A['X_233'] != -999999) | (train_A['X_234'] != -999999) | (train_A['X_235'] != -999999) | (train_A['X_236'] != -999999)]\n",
    "train_T_2_indices = train_T.index[(train_T['X_3000'] != -999999) | (train_T['X_3001'] != -999999) | (train_T['X_3002'] != -999999) | (train_T['X_3003'] != -999999) | (train_T['X_3004'] != -999999) | (train_T['X_3005'] != -999999) | (train_T['X_3006'] != -999999)]\n",
    "#train_O_2_indices = train_O.index[(train_O['X_93'] != -999999) | (train_O['X_94'] != -999999) | (train_O['X_95'] != -999999) | (train_O['X_96'] != -999999)]\n",
    "\n",
    "train_A_2 = train_A.loc[train_A_2_indices]\n",
    "train_T_2 = train_T.loc[train_T_2_indices]\n",
    "#train_O_2 = train_O.loc[train_O_2_indices]\n",
    "\n",
    "test_A_1_indices = test_A.index[(test_A['X_230'] == -999999) & (test_A['X_231'] == -999999) & (test_A['X_232'] == -999999) & (test_A['X_233'] == -999999) & (test_A['X_234'] == -999999) & (test_A['X_235'] == -999999) & (test_A['X_236'] == -999999)]\n",
    "test_T_1_indices = test_T.index[(test_T['X_3000'] == -999999) & (test_T['X_3001'] == -999999) & (test_T['X_3002'] == -999999) & (test_T['X_3003'] == -999999) & (test_T['X_3004'] == -999999) & (test_T['X_3005'] == -999999) & (test_T['X_3006'] == -999999)]\n",
    "#test_O_1_indices = test_O.index[(test_O['X_93'] == -999999) & (test_O['X_94'] == -999999) & (test_O['X_95'] == -999999) & (test_O['X_96'] == -999999)]\n",
    "\n",
    "test_A_1 = test_A.loc[test_A_1_indices]\n",
    "test_T_1 = test_T.loc[test_T_1_indices]\n",
    "#test_O_1 = test_O.loc[test_O_1_indices]\n",
    "\n",
    "test_A_2_indices = test_A.index[(test_A['X_230'] != -999999) | (test_A['X_231'] != -999999) | (test_A['X_232'] != -999999) | (test_A['X_233'] != -999999) | (test_A['X_234'] != -999999) | (test_A['X_235'] != -999999) | (test_A['X_236'] != -999999)]\n",
    "test_T_2_indices = test_T.index[(test_T['X_3000'] != -999999) | (test_T['X_3001'] != -999999) | (test_T['X_3002'] != -999999) | (test_T['X_3003'] != -999999) | (test_T['X_3004'] != -999999) | (test_T['X_3005'] != -999999) | (test_T['X_3006'] != -999999)]\n",
    "#test_O_2_indices = test_O.index[(test_O['X_93'] != -999999) | (test_O['X_94'] != -999999) | (test_O['X_95'] != -999999) | (test_O['X_96'] != -999999)]\n",
    "\n",
    "test_A_2 = test_A.loc[test_A_2_indices]\n",
    "test_T_2 = test_T.loc[test_T_2_indices]\n",
    "#test_O_2 = test_O.loc[test_O_2_indices]\n",
    "\n",
    "submit_A_1 = submit_A.loc[test_A_1_indices]\n",
    "submit_T_1 = submit_T.loc[test_T_1_indices]\n",
    "#submit_O_1 = submit_O.loc[test_O_1_indices]\n",
    "\n",
    "submit_A_2 = submit_A.loc[test_A_2_indices]\n",
    "submit_T_2 = submit_T.loc[test_T_2_indices]\n",
    "#submit_O_2 = submit_O.loc[test_O_2_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m--S5xcaNagu"
   },
   "outputs": [],
   "source": [
    "train_A_1, test_A_1 = del_columns(train_A_1,test_A_1)\n",
    "train_T_1, test_T_1 = del_columns(train_T_1,test_T_1)\n",
    "#train_O_1, test_O_1 = del_columns(train_O_1,test_O_1)\n",
    "\n",
    "train_A_2, test_A_2 = del_columns(train_A_2,test_A_2)\n",
    "train_T_2, test_T_2 = del_columns(train_T_2,test_T_2)\n",
    "#train_O_2, test_O_2 = del_columns(train_O_2,test_O_2)\n",
    "\n",
    "train_O, test_O = del_columns(train_O,test_O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyViVrP2OY6S"
   },
   "outputs": [],
   "source": [
    "train_A_1_x, test_A_1_x, train_A_1_y, train_A_1_w = make_train_test_dataset(train_A_1,test_A_1)\n",
    "train_A_2_x, test_A_2_x, train_A_2_y, train_A_2_w = make_train_test_dataset(train_A_2,test_A_2)\n",
    "\n",
    "train_T_1_x, test_T_1_x, train_T_1_y, train_T_1_w  = make_train_test_dataset(train_T_1,test_T_1)\n",
    "train_T_2_x, test_T_2_x, train_T_2_y, train_T_2_w  = make_train_test_dataset(train_T_2,test_T_2)\n",
    "\n",
    "train_O_x, test_O_x, train_O_y, train_O_w = make_train_test_dataset(train_O,test_O)\n",
    "\n",
    "#train_O_1_x, test_O_1_x, train_O_1_y, train_O_1_w = make_train_test_dataset(train_O_1,test_O_1)\n",
    "#train_O_2_x, test_O_2_x, train_O_2_y, train_O_2_w = make_train_test_dataset(train_O_2,test_O_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjsYWc3NWlD3"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import copy\n",
    "from itertools import product\n",
    "\n",
    "def get_best_threshold_spliter(y_pred, y_true_cls, model=None, training=True):\n",
    "    if training:\n",
    "        #search_space = [[2, 4, 6, 18, 36], [1, 3, 5, 7, 9, 27, 54]]\n",
    "        search_space = [[2, 4, 6], [1, 3, 5, 7, 9]]\n",
    "        best_score = -np.inf\n",
    "        output_pred = []\n",
    "        model = None\n",
    "        for depth, min_samples in product(*search_space): \n",
    "            model = DecisionTreeClassifier(\n",
    "                criterion=\"gini\", max_features=1.0,\n",
    "                max_depth=depth, min_samples_leaf=min_samples, random_state=42\n",
    "            )\n",
    "\n",
    "            model.fit(y_pred, y_true_cls)\n",
    "            y_pred_cls = model.predict(y_pred)\n",
    "            score = metrics.f1_score(y_true_cls, y_pred_cls, average=\"macro\")\n",
    "            if ((best_score < score)):\n",
    "                best_score = score\n",
    "                print(f\"Best score : {best_score}\")\n",
    "                output_pred = y_pred_cls.copy()\n",
    "                model = copy.deepcopy(model)\n",
    "        return model, output_pred\n",
    "    else:\n",
    "        output_pred = model.predict(y_pred)\n",
    "        return output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om87u1lmXKWm"
   },
   "outputs": [],
   "source": [
    "A1_stats = pd.DataFrame({\"qual\": train_A_1_y, \"cls\": train_A_1_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "A2_stats = pd.DataFrame({\"qual\": train_A_2_y, \"cls\": train_A_2_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "\n",
    "T1_stats = pd.DataFrame({\"qual\": train_T_1_y, \"cls\": train_T_1_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "T2_stats = pd.DataFrame({\"qual\": train_T_2_y, \"cls\": train_T_2_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()\n",
    "\n",
    "O_stats = pd.DataFrame({\"qual\": train_O_y, \"cls\": train_O_w[\"Y_Class\"]}).groupby(\"cls\")[\"qual\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "EBNOudnSeO9q",
    "outputId": "c5c21b76-0684-4c79-dfc6-98c2f0376b6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-88d55c4e-b24d-4a39-bf1b-e1ca59a2ac9a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.530601</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.525916</td>\n",
       "      <td>0.529938</td>\n",
       "      <td>0.530954</td>\n",
       "      <td>0.532101</td>\n",
       "      <td>0.533702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.535078</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.534951</td>\n",
       "      <td>0.535014</td>\n",
       "      <td>0.535078</td>\n",
       "      <td>0.535141</td>\n",
       "      <td>0.535205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88d55c4e-b24d-4a39-bf1b-e1ca59a2ac9a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-88d55c4e-b24d-4a39-bf1b-e1ca59a2ac9a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-88d55c4e-b24d-4a39-bf1b-e1ca59a2ac9a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     count      mean       std       min       25%       50%       75%  \\\n",
       "cls                                                                      \n",
       "1      6.0  0.530601  0.002681  0.525916  0.529938  0.530954  0.532101   \n",
       "2      2.0  0.535078  0.000180  0.534951  0.535014  0.535078  0.535141   \n",
       "\n",
       "          max  \n",
       "cls            \n",
       "1    0.533702  \n",
       "2    0.535205  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSR_rq3uPN62"
   },
   "outputs": [],
   "source": [
    "#1\n",
    "clf = catboost.CatBoostRegressor(\n",
    "    learning_rate=0.05,# 0.05\n",
    "    iterations=1000, #1000\n",
    "    depth=6,\n",
    "    l2_leaf_reg=5, #5\n",
    "    border_count=254,cat_features=['LINE'],\n",
    "    random_seed=313)\n",
    "##################\n",
    "clf.fit(train_A_1_x, train_A_1_y)\n",
    "train_pred_A1 = clf.predict(train_A_1_x)\n",
    "pred_A1 = clf.predict(test_A_1_x)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    train_pred_A1 - A1_stats.loc[0, \"mean\"],\n",
    "    train_pred_A1 - A1_stats.loc[1, \"mean\"],\n",
    "    train_pred_A1 - A1_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "model_threshold, train_pred_A1 = get_best_threshold_spliter(reg_prob, train_A_1_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    pred_A1 - A1_stats.loc[0, \"mean\"],\n",
    "    pred_A1 - A1_stats.loc[1, \"mean\"],\n",
    "    pred_A1 - A1_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "pred_A1 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n",
    "##################\n",
    "clf.fit(train_A_2_x, train_A_2_y)\n",
    "train_pred_A2 = clf.predict(train_A_2_x)\n",
    "pred_A2 = clf.predict(test_A_2_x)\n",
    "reg_prob = np.abs(np.stack([\n",
    "    train_pred_A2 - A2_stats.loc[0, \"mean\"],\n",
    "    train_pred_A2 - A2_stats.loc[1, \"mean\"],\n",
    "    train_pred_A2 - A2_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "model_threshold, train_pred_A2 = get_best_threshold_spliter(reg_prob, train_A_2_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    pred_A2 - A2_stats.loc[0, \"mean\"],\n",
    "    pred_A2 - A2_stats.loc[1, \"mean\"],\n",
    "    pred_A2 - A2_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "pred_A2 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "clf.fit(train_T_1_x, train_T_1_y)\n",
    "train_pred_T1 = clf.predict(train_T_1_x)\n",
    "pred_T1 = clf.predict(test_T_1_x)\n",
    "reg_prob = np.abs(np.stack([\n",
    "    train_pred_T1 - T1_stats.loc[0, \"mean\"],\n",
    "    train_pred_T1 - T1_stats.loc[1, \"mean\"],\n",
    "    train_pred_T1 - T1_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "model_threshold, train_pred_T1 = get_best_threshold_spliter(reg_prob, train_T_1_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    pred_T1 - T1_stats.loc[0, \"mean\"],\n",
    "    pred_T1 - T1_stats.loc[1, \"mean\"],\n",
    "    pred_T1 - T1_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "pred_T1 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "clf.fit(train_T_2_x, train_T_2_y)\n",
    "train_pred_T2 = clf.predict(train_T_2_x)\n",
    "pred_T2 = clf.predict(test_T_2_x)\n",
    "reg_prob = np.abs(np.stack([\n",
    "    train_pred_T2 - T2_stats.loc[0, \"mean\"],\n",
    "    train_pred_T2 - T2_stats.loc[1, \"mean\"],\n",
    "    train_pred_T2 - T2_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "model_threshold, train_pred_T2 = get_best_threshold_spliter(reg_prob, train_T_2_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    pred_T2 - T2_stats.loc[0, \"mean\"],\n",
    "    pred_T2 - T2_stats.loc[1, \"mean\"],\n",
    "    pred_T2 - T2_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "pred_T2 = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "clf.fit(train_O_x, train_O_y)\n",
    "train_pred_O = clf.predict(train_O_x)\n",
    "pred_O = clf.predict(test_O_x)\n",
    "reg_prob = np.abs(np.stack([\n",
    "    train_pred_O - O_stats.loc[1, \"mean\"],\n",
    "    train_pred_O - O_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "model_threshold, train_pred_O = get_best_threshold_spliter(reg_prob, train_O_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    pred_O - O_stats.loc[1, \"mean\"],\n",
    "    pred_O - O_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "pred_O = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9jzxsEoeRCF"
   },
   "outputs": [],
   "source": [
    "clf.fit(train_O_x, train_O_y)\n",
    "train_pred_O = clf.predict(train_O_x)\n",
    "pred_O = clf.predict(test_O_x)\n",
    "reg_prob = np.abs(np.stack([\n",
    "    #train_pred_O - O_stats.loc[0, \"mean\"],\n",
    "    train_pred_O - O_stats.loc[1, \"mean\"],\n",
    "    train_pred_O - O_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "model_threshold, train_pred_O = get_best_threshold_spliter(reg_prob, train_O_w[\"Y_Class\"].values, training=True)\n",
    "\n",
    "reg_prob = np.abs(np.stack([\n",
    "    #pred_O - O_stats.loc[0, \"mean\"],\n",
    "    pred_O - O_stats.loc[1, \"mean\"],\n",
    "    pred_O - O_stats.loc[2, \"mean\"],\n",
    "], axis=1))\n",
    "pred_O = get_best_threshold_spliter(reg_prob, y_true_cls=None, model=model_threshold, training=False)\n",
    "##################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X54J4kp8enxa"
   },
   "outputs": [],
   "source": [
    "submit_A_1['Y_Class'] = pred_A1\n",
    "submit_A_2['Y_Class'] = pred_A2\n",
    "\n",
    "submit_T_1['Y_Class'] = pred_T1\n",
    "submit_T_2['Y_Class'] = pred_T2\n",
    "\n",
    "submit_O['Y_Class'] = pred_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8lWXg94euVI",
    "outputId": "4d9b61ea-ed77-449e-ddf8-c50458cc9772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    414\n",
       "2     76\n",
       "0     45\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_combined = pd.concat([submit_A_1, submit_A_2, submit_T_1, submit_T_2, submit_O], axis=0)\n",
    "submit_combined = submit_combined.reset_index(drop=True)\n",
    "submit_combined = submit_combined.sort_values('PRODUCT_ID')\n",
    "submit_combined.drop(['PRODUCT_CODE'],axis=1,inplace=True)\n",
    "submit_combined = submit_combined.reset_index(drop=True)\n",
    "submit_combined.to_csv('upgrade1_dt.csv',index=False)\n",
    "submit_combined['Y_Class'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
